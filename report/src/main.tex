% Preamble
\documentclass[11pt]{report}

% Packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{color}
\usepackage[table,xcdraw]{xcolor}
\usepackage{multirow}
\usepackage{float}
\usepackage{booktabs}

\usepackage[margin=2.5cm]{geometry}
\usepackage{hyperref}
\usepackage{cleveref}

\usepackage[symbol]{footmisc}


%% Custom commands
\newcommand*\apos{\textsc{\char13}}

% set image file paths
%\graphicspath{ {../../fuzzy/output/mamdani\_bell\_v9/io\_graphs/} }


\title{Fuzzy Systems and Neural Networks}
\author{Jéssica Consciência e Tiago Leite}


\begin{document}
\maketitle
\newpage


\part{Fuzzy System}

%% Texto ainda por melhorar!!
Firstly we started by deciding between which type of fuzzy system
we should implement: Mamdani, Takagi-Sugeno or Tsukamoto. From the
project statement we observe that the output \textit{CLPVariation}
is not any clear function of the input, rulling out Takagi-Sugeno,
also meaning that our output is a \textbf{Fuzzy Set}. If we wish for
our output to be monotonic then the choice would be Tsukomoto, since
we did not want this restriction and decided for starting with a simple
approach then later on adding difficulty when needed.
(Early on we decided to try to make data-driven decisions with an iterative
improving process)

\section{First Iterations}

In the initial iteration, we selected the variables \textit{ProcessorLoad}, \textit{MemoryUsage}, and \textit{Latency} based on common sense.
These variables were chosen as inputs, while \textit{CLP} was designated as the output.
We opted for triangular membership functions, defining four levels for each input variable: (low, medium, high, critical) for \textit{ProcessorLoad} and \textit{MemoryUsage}, and (poor, fair, good, great) for \textit{Latency}.

To start building the system, we decided to focus on just two variables: \textit{MemoryUsage} and \textit{ProcessorLoad}.
We then defined the range of the membership functions associated with each term of the two linguistic variables.
Considering that a device with more than 85\% processor load or memory usage is typically unable to perform its basic tasks,
it became clear that this threshold would correspond to a specific term, which we labeled as ``critical''. The ranges for the other membership function terms were distributed between 0 and 1 based on what we deemed appropriate.
We also decided to keep the terms associated with \textit{CLP} straightforward, using only three terms: ``decrease'', ``increase'', and ``maintain''.
The values for the membership functions of these terms were distributed between -1 and 1.

The figures below illustrate the membership function graphs for these variables.

\begin{figure}[htbp]
    \centering
    \begin{minipage}{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{../images/triangular_MemoryUsage}
        \caption{Memory Usage}
        \label{fig:processor_load}
    \end{minipage}
    \hfill
    \begin{minipage}{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{../images/triangular_ProcessorLoad}
        \caption{Processor Load}
        \label{fig:memory_usage}
    \end{minipage}
    \hfill
    \begin{minipage}{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{../images/triangular_CLP}
        \caption{CLP Variation}
        \label{fig:clp}
    \end{minipage}
\end{figure}


To design the system's rules, we created a truth table, which can be found below in Table~\ref{truthtable}.
The logic behind the table was as follows: when both \textit{MemoryUsage} and \textit{ProcessorLoad} were either ``low'' or ``medium'', the \textit{CLP} would increase.
When one of them reached ``high'', the \textit{CLP} remained unchanged (this decision was made to ensure that the node's processing capacity stayed above average).
Finally, if any of these variables entered a ``critical'' state, the \textit{CLP} had to decrease.


\begin{table}[htbp]
    \centering
    \begin{tabular}{|
            >{\columncolor[HTML]{FFFFFF}}c
            >{\columncolor[HTML]{FFFFFF}}c |cccc|}
        \hline
        \multicolumn{2}{|c|}{\cellcolor[HTML]{FFFFFF}} & \multicolumn{4}{c|}{\cellcolor[HTML]{FFFFFF}\textit{ProcessorLoad}} \\ \cline{3-6}
        \multicolumn{2}{|c|}{\multirow{-2}{*}{\cellcolor[HTML]{FFFFFF}\textit{CLP}}} & \multicolumn{1}{c|}{\cellcolor[HTML]{FFFFFF}low} & \multicolumn{1}{c|}{\cellcolor[HTML]{FFFFFF}medium} & \multicolumn{1}{c|}{\cellcolor[HTML]{FFFFFF}high} & \cellcolor[HTML]{FFFFFF}critical \\ \hline
        \multicolumn{1}{|c|}{\cellcolor[HTML]{FFFFFF}}                                       & low      & \multicolumn{1}{c|}{increase}                    & \multicolumn{1}{c|}{increase}                       & \multicolumn{1}{c|}{maintain}                      & decrease                         \\ \cline{2-6}
        \multicolumn{1}{|c|}{\cellcolor[HTML]{FFFFFF}}                                       & medium   & \multicolumn{1}{c|}{increase}                    & \multicolumn{1}{c|}{increase}                       & \multicolumn{1}{c|}{maintain}                     & decrease                         \\ \cline{2-6}
        \multicolumn{1}{|c|}{\cellcolor[HTML]{FFFFFF}}                                       & high     & \multicolumn{1}{c|}{maintain}                    & \multicolumn{1}{c|}{maintain}                       & \multicolumn{1}{c|}{maintain}                     & decrease                         \\ \cline{2-6}
        \multicolumn{1}{|c|}{\multirow{-4}{*}{\cellcolor[HTML]{FFFFFF}\textit{MemoryUsage}}} & critical & \multicolumn{1}{c|}{decrease}                    & \multicolumn{1}{c|}{decrease}                       & \multicolumn{1}{c|}{decrease}                     & decrease                         \\ \hline
    \end{tabular}
    \caption{Truth table}
    \label{truthtable}
\end{table}




To visualize the system's output, we generated 50 data points for \textit{MemoryUsage} and \textit{ProcessorLoad} ranging between 0 and 1.
We then created an interactive 3D graph that showed the evolution of \textit{CLP} based on these two values.


Subsequently, we explored the effect of switching the membership functions to a Gaussian distribution.

\begin{figure}[h]
    \centering
%\includegraphics{path_to_gaussian_graph}
%\caption{3D visualization of Gaussian membership functions}
\end{figure}

During the experimentation phase with different membership functions, the need for visualization became apparent.
To facilitate this, we developed a helper script [fuzzy/visualization/fuzzy\_system\_to\_dataframe] that converts the
FuzzySystem Python object into a dynamic dataframe, enabling easy plotting and analysis of the membership functions.


\section{Generalized Bell}
We decided to experiment with a more generic Membership function, so we
extended simpful's Base Membership Function class and created Bell\_MF [in fuzzy/models/bell\_mf.py].
The first results are shown in the figure bellow.


\begin{figure}[htbp]
    \centering
    \begin{minipage}{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{../images/first_bell/MemoryUsage}
        \caption{Memory Usage}
        \label{fig:first_bell_processor_load}
    \end{minipage}
    \hfill
    \begin{minipage}{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{../images/first_bell/ProcessorLoad}
        \caption{Processor Load}
        \label{fig:first_bell_memory_usage}
    \end{minipage}
    \hfill
    \begin{minipage}{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{../images/first_bell/CLP}
        \caption{CLP Variation}
        \label{fig:first_bell_clp}
    \end{minipage}
\end{figure}


After some experimentation, we concluded (as foreseen theoretically) that the parameters $a$, $b$, and $c$ are responsible for the slope\footnote[1]{The slope of the function is influenced by both parameters $a$ and $b$, where $slope = \frac{a}{2b}$}, width, and center of the function, respectively.

%\includegraphics[width=0.5]{../../fuzzy/output/mamdani_bell/io_graphs/MemoryUsage.png}
%\includegraphics[width=0.5]{../../fuzzy/output/mamdani_bell/io_graphs/ProcessorLoad.png}
%\includegraphics[width=0.5]{../../fuzzy/output/mamdani_bell/io_graphs/CLP.png}

%%


\section{Architecture}
This should contain choice of architecture and why.

\begin{table}[H]
    \begin{tabular}{|
            >{\columncolor[HTML]{9698ED}}c l|cccc|}
        \hline
        \multicolumn{2}{|c|}{\cellcolor[HTML]{FFCC67}{\color[HTML]{333333} }} & \multicolumn{4}{c|}{\cellcolor[HTML]{9698ED}Latency} \\ \cline{3-6}
        \multicolumn{2}{|c|}{\multirow{-2}{*}{\cellcolor[HTML]{FFCC67}{\color[HTML]{333333} CLP Variation}}} & \multicolumn{1}{l|}{low} & \multicolumn{1}{l|}{moderate} & \multicolumn{1}{l|}{high} & \multicolumn{1}{l|}{very high} \\ \hline
        \multicolumn{1}{|c|}{\cellcolor[HTML]{9698ED}}                              & low      & \multicolumn{1}{c|}{IS} & \multicolumn{1}{c|}{IS}       & \multicolumn{1}{c|}{I}    & I                              \\ \cline{2-6}
        \multicolumn{1}{|c|}{\cellcolor[HTML]{9698ED}}                              & moderate & \multicolumn{1}{c|}{I}  & \multicolumn{1}{c|}{I}        & \multicolumn{1}{c|}{I}    & I                              \\ \cline{2-6}
        \multicolumn{1}{|c|}{\cellcolor[HTML]{9698ED}}                              & high     & \multicolumn{1}{c|}{M}  & \multicolumn{1}{c|}{M}        & \multicolumn{1}{c|}{D}    & D                              \\ \cline{2-6}
        \multicolumn{1}{|c|}{\multirow{-4}{*}{\cellcolor[HTML]{9698ED}System Load}} & critical        & \multicolumn{1}{c|}{DS}  & \multicolumn{1}{c|}{DS}       & \multicolumn{1}{c|}{DS}   & DS                             \\ \hline
    \end{tabular}
\end{table}


\section{Evaluate Models}
Now that we had developed several models and established rules, a reliable and straightforward testing mechanism became necessary.
To achieve this, we implemented the script \texttt{eval\_models.py} (\texttt{fuzzy/eval\_models.py}),
which utilizes a dictionary to compare all model predictions on 10 expert sample data points provided in \texttt{CINTE24-25\_Proj1\_SampleData.csv}.
Initially, the relative error metric, defined as:

\[
    \text{Relative Error} = \frac{|y_{\text{true}} - y_{\text{pred}}|}{y_{\text{true}}}
\]

was used for evaluation.
However, this metric exhibited instability when $y_{\text{true}} \to 0$, as was the case for data point 6 in the sample.
This issue is illustrated in the figure below, where the models \texttt{mamdani\_triangle\_v2}, \texttt{mamdani\_bell\_v9}, and \texttt{mamdani\_best} are compared.

\begin{figure}[htpb]
\includegraphics[width=\textwidth]{../images/eval_models/relative_error}
\end{figure}

To address this instability, we switched to the Mean Squared Error (MSE) metric, defined as:

\[
    \text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_{\text{true}} - y_{\text{pred}})^2
\]

The results of this evaluation are presented below.

\begin{figure}[H]
\includegraphics[width=\textwidth]{../images/eval_models/mse}
\end{figure}

This evaluation process was instrumental in improving our models and identifying potential problem areas.
For instance, the model consistently underestimated the CLP for data points 3 and 4, this is shown in the table below.

\begin{table}[H]
    \centering
    \caption{Sample data points 3 and 4}
    \label{tab:}
    \begin{tabular}{lrrrrr}
        \toprule
        & MemoryUsage & ProcessorLoad & Latency & mamdani\_bell\_v2 & CLPVariation \\
        \midrule
        3 & 0.68        & 0.60          & 0.80    & 0.30              & 0.73         \\
        4 & 0.50        & 0.50          & 0.50    & 0.66              & 0.50         \\
        \bottomrule
    \end{tabular}
\end{table}



These observations suggested, in our view, that the model should account for high latency as a factor contributing to a lower \emph{CLP}.
This iterative process led to the development of models like \texttt{mamdani\_triangle\_v2} and \texttt{mamdani\_bell\_v9}.
Many more iterations were tested but not preserved.
Some of the deprecated models can still be found in the \texttt{fuzzy/models/deprecated} folder, along with their outputs in \texttt{fuzzy/output/deprecated}.

The best model, \texttt{mamdani\_best}, emerged as the result of extensive hyperparameter tuning, which is discussed in detail in the~\nameref{sec:hyper_tuning} section.


\section{Hyperparameter Tuning}
\label{sec:hyper_tuning}

Since we had manually iterated until a good model was reached, scoring 0.0447 in total MSE on the 10 sample data points, we considered the linguistic variables and rule base as fixed.
However, we found ourselves tirelessly fine-tuning the membership functions, such as the center, slope, and width in the case of the bell membership function.
To automate this process, we took the following steps:

\begin{itemize}
    \item Create a \texttt{FuzzySystem} from a set of hyperparameters [\texttt{fuzzy/models/mamdani\_hparams.py}].
    \item Define an objective function to minimize/maximize.
          In our case, we used the total MSE of the 10 sample data points as the objective value to be minimized.
    \item Sample several hyperparameter trials and find the best.
          This was done with the help of the Python framework \texttt{optuna}, which uses Bayesian Optimization to find optimal hyperparameters.
\end{itemize}

A simpler approach would have been to use \texttt{RandomSearch} or \texttt{GridSearch} (possibly using \texttt{scikit-learn}).
However, we chose to leverage \texttt{optuna}\apos s search algorithm, Tree Parzen Estimation (TPE).
In a nutshell, TPE builds an internal model that makes ``educated'' guesses about which hyperparameters to test and continuously updates that model.
The search is then performed in a tree-like manner, and \texttt{optuna} can handle both continuous and categorical data.

After 3 hours of hyperparameter tuning, the \texttt{mamdani\_bell\_v9} model, comprising a total of 6228 trials, achieved a final total MSE of $0.00749$.
This corresponds to a six-fold improvement over the manually obtained $MSE$ of $0.04473$.
The best hyperparameters from this tuning process were saved as \texttt{hparams\_007.json}.


\section{Conclusion}


\part{Neural Networks}

\section{Architecture}

To build the neural network, we decided to use a simple architecture: 3 layers, 12 input nodes, 32 nodes in the hidden layer, and 1 output node.
Since the output should be in the range \([-1, 1]\), we chose the \emph{Tanh} activation function, which produces values within this range.
For the optimizer, we used Adam with a learning rate of $1 \times 10^{-3}$, leaving the rest of the parameters at their default values: $\epsilon = 1 \times 10^{-8}$, $\beta = (0.9, 0.999)$, and \texttt{weight\_decay} = 0.
For the loss function, we chose MSE, allowing us to directly compare the results with those of the Fuzzy System.

We implemented the neural network using the PyTorch framework alongside \texttt{pytorch\_lightning}.
This made it easy to integrate TensorBoard for logging and visualization, apply Early Stopping to prevent unnecessary computation, and enable Model Checkpointing to save the best-performing model.
This code can be found in the \texttt{nn/models/simple\_lightning.py} file.

\section{Training Data}

To create the training data for the neural network, we began by generating synthetic data for the $12$ input features.
This was done by sampling $100.000$ random uniformly distributed values for each feature.
Next, the Fuzzy System was used to predict the CLPVariation, utilizing the best-performing Fuzzy System located in \texttt{fuzzy/models/mamdani\_best.py}.
The results were then stored in a CSV file inside the \texttt{gen\_input} folder.
This code can be found in the \texttt{fuzzy/generate\_data.py} file.
The decision to use random uniform data, as opposed to, for example, a Gaussian distribution, was made to ensure a \textbf{balanced} dataset for training the neural network.
The choice of the number of training data samples was also carefully considered.
We followed the rule of thumb that ``a model will often need ten times more data than it has degrees of freedom'', where a degree of freedom refers to model parameters or input features.
Our model has 449 trainable parameters and 12 input features, which means our training data should consist of more than $4610$ samples.
We decided to generate a number of samples equal to an order of magnitude above 4610 rounded up, which results in 100,000 samples.



\end{document}
